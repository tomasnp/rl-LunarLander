#!/usr/bin/env python3
"""
A2C Gradual - AmÃ©liorations PROGRESSIVES (moins agressives)
Commence avec le baseline et ajoute UNE amÃ©lioration Ã  la fois
"""

import sys
sys.path.insert(0, '.')

from A2C import Config, train, setup_logging

if __name__ == "__main__":
    # Setup logging
    log_filepath, tee_logger = setup_logging(log_dir="logs", experiment_name="a2c_gradual")
    sys.stdout = tee_logger

    try:
        cfg = Config()

        # ============================================================
        # AMÃ‰LIORATION GRADUELLE #1: Network plus large SEULEMENT
        # ============================================================

        # Baseline hyperparamÃ¨tres (prouvÃ©s)
        cfg.lr_policy = 5e-4
        cfg.lr_value = 1e-3
        cfg.entropy_coef_start = 0.05
        cfg.entropy_coef_final = 0.005
        cfg.value_coef = 0.5
        cfg.rollout_steps = 2048
        cfg.max_updates = 10000
        cfg.eval_every = 50
        cfg.eval_episodes = 30
        cfg.grad_clip = 0.5

        # AMÃ‰LIORATION #1: Network plus large (moins risquÃ©)
        cfg.hidden_size = 512  # â† Compromis entre 256 et 512

        # Autres amÃ©liorations DÃ‰SACTIVÃ‰ES pour l'instant
        cfg.normalize_obs = False     # â† Peut causer instabilitÃ©
        cfg.reward_clip = None        # â† Peut perturber signal
        cfg.weight_decay = 1e-6       # â† TrÃ¨s faible pour commencer

        # Checkpoint
        cfg.save_name = f"a2c_r_{cfg.rollout_steps}_u_{cfg.max_updates}_h_{cfg.hidden_size}.pt"
        cfg.plot_name = f"a2c_r_{cfg.rollout_steps}_u_{cfg.max_updates}_h_{cfg.hidden_size}.png"

        print("="*80)
        print("ğŸ”¬ A2C GRADUAL - AmÃ©liorations Progressives")
        print("="*80)
        print(f"Hidden size: {cfg.hidden_size} (baseline=256, full=512)")
        print(f"Weight decay: {cfg.weight_decay} (trÃ¨s faible)")
        print()
        print("âœ… AMÃ‰LIORATIONS ACTIVÃ‰ES:")
        print(f"  â€¢ Hidden size augmentÃ©: 256 â†’ {cfg.hidden_size}")
        print(f"  â€¢ Weight decay minimal: {cfg.weight_decay}")
        print()
        print("âŒ AMÃ‰LIORATIONS EN ATTENTE:")
        print(f"  â€¢ Observation normalization: {cfg.normalize_obs}")
        print(f"  â€¢ Reward clipping: {cfg.reward_clip}")
        print()
        print("ğŸ¯ OBJECTIF: 220+ reward, 80-85% success")
        print("="*80 + "\n")

        # EntraÃ®ner
        history = train(cfg)

        print("\n" + "="*80)
        print("âœ… EntraÃ®nement terminÃ©!")
        print()
        print("ğŸ“Š Si rÃ©sultats > baseline (200, 74.8%):")
        print("   â†’ Activez normalisation dans prochaine itÃ©ration")
        print()
        print("ğŸ“Š Si rÃ©sultats â‰ˆ baseline:")
        print("   â†’ Hidden size 384 ne change pas grand chose")
        print("   â†’ Essayez 512 ou activez normalisation")
        print()
        print("ğŸ“Š Si rÃ©sultats < baseline:")
        print("   â†’ Revenez Ã  hidden=256")
        print("   â†’ ProblÃ¨me ailleurs (seed, env, etc.)")
        print("="*80)

    finally:
        # Restore stdout and close log
        sys.stdout = tee_logger.terminal
        tee_logger.close()
        print(f"\nâœ… Log saved to: {log_filepath}")
